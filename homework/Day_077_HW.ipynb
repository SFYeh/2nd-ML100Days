{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work\n",
    "1. 請將 Epoch 加到 500 個，並觀察 learning curve 的走勢\n",
    "2. 請將 Optimizer 換成 SGD，並觀察 learning curve 的走勢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANS：OVERFITING的情形相較於範例，感覺還好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import keras\n",
    "\n",
    "# 本作業可以不需使用 GPU, 將 GPU 設定為 \"無\" (若有 GPU 且想開啟，可設為 \"0\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 從 Keras 的內建功能中，取得 train 與 test 資料集\n",
    "train, test = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將 X 與 Y 獨立放進變數\n",
    "x_train, y_train = train\n",
    "x_test, y_test = test\n",
    "# 資料前處理 - 標準化\n",
    "x_train = x_train / 255.\n",
    "x_test = x_test / 255.\n",
    "\n",
    "# 將資料從圖形 (RGB) 轉為向量 (Single Vector)\n",
    "x_train = x_train.reshape((len(x_train), -1))\n",
    "x_test = x_test.reshape((len(x_test), -1))\n",
    "\n",
    "# 將目標轉為 one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp():\n",
    "    input_layer = keras.layers.Input([x_train.shape[-1]])\n",
    "    x = keras.layers.Dense(units=512, activation=\"relu\")(input_layer)\n",
    "    x = keras.layers.Dense(units=256, activation=\"relu\")(x)\n",
    "    out = keras.layers.Dense(units=10, activation=\"softmax\")(x)\n",
    "    \n",
    "    model = keras.models.Model(inputs=[input_layer], outputs=[out])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\programfiles\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\programfiles\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\programfiles\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = build_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\programfiles\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\programfiles\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Compile 模型\n",
    "\"\"\"\n",
    "optimizer = keras.optimizers.SGD(lr=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\programfiles\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From D:\\programfiles\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\programfiles\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\programfiles\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/500\n",
      "WARNING:tensorflow:From D:\\programfiles\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\programfiles\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\programfiles\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\programfiles\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From D:\\programfiles\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 2.2474 - acc: 0.1851 - val_loss: 2.1936 - val_acc: 0.2246\n",
      "Epoch 2/500\n",
      "50000/50000 [==============================] - 5s 105us/step - loss: 2.1597 - acc: 0.2396 - val_loss: 2.1262 - val_acc: 0.2499\n",
      "Epoch 3/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 2.1026 - acc: 0.2615 - val_loss: 2.0775 - val_acc: 0.2705\n",
      "Epoch 4/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 2.0591 - acc: 0.2787 - val_loss: 2.0395 - val_acc: 0.2820\n",
      "Epoch 5/500\n",
      "50000/50000 [==============================] - 7s 148us/step - loss: 2.0248 - acc: 0.2912 - val_loss: 2.0098 - val_acc: 0.2974\n",
      "Epoch 6/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.9968 - acc: 0.3031 - val_loss: 1.9850 - val_acc: 0.3091\n",
      "Epoch 7/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.9736 - acc: 0.3133 - val_loss: 1.9626 - val_acc: 0.3142\n",
      "Epoch 8/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.9531 - acc: 0.3231 - val_loss: 1.9440 - val_acc: 0.3278\n",
      "Epoch 9/500\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.9353 - acc: 0.3312 - val_loss: 1.9267 - val_acc: 0.3294\n",
      "Epoch 10/500\n",
      "50000/50000 [==============================] - 8s 152us/step - loss: 1.9195 - acc: 0.3368 - val_loss: 1.9127 - val_acc: 0.3369\n",
      "Epoch 11/500\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 1.9054 - acc: 0.3430 - val_loss: 1.8998 - val_acc: 0.3419\n",
      "Epoch 12/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.8926 - acc: 0.3460 - val_loss: 1.8867 - val_acc: 0.3488\n",
      "Epoch 13/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.8810 - acc: 0.3509 - val_loss: 1.8758 - val_acc: 0.3506\n",
      "Epoch 14/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.8706 - acc: 0.3542 - val_loss: 1.8657 - val_acc: 0.3568\n",
      "Epoch 15/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.8609 - acc: 0.3581 - val_loss: 1.8568 - val_acc: 0.3567\n",
      "Epoch 16/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.8518 - acc: 0.3602 - val_loss: 1.8496 - val_acc: 0.3610\n",
      "Epoch 17/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.8434 - acc: 0.3639 - val_loss: 1.8417 - val_acc: 0.3637\n",
      "Epoch 18/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.8356 - acc: 0.3665 - val_loss: 1.8328 - val_acc: 0.3693\n",
      "Epoch 19/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.8283 - acc: 0.3692 - val_loss: 1.8268 - val_acc: 0.3694\n",
      "Epoch 20/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.8216 - acc: 0.3706 - val_loss: 1.8190 - val_acc: 0.3721\n",
      "Epoch 21/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.8147 - acc: 0.3734 - val_loss: 1.8138 - val_acc: 0.3733\n",
      "Epoch 22/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.8087 - acc: 0.3756 - val_loss: 1.8070 - val_acc: 0.3751\n",
      "Epoch 23/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.8024 - acc: 0.3771 - val_loss: 1.8014 - val_acc: 0.3776\n",
      "Epoch 24/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.7966 - acc: 0.3789 - val_loss: 1.7967 - val_acc: 0.3754\n",
      "Epoch 25/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.7909 - acc: 0.3803 - val_loss: 1.7902 - val_acc: 0.3817\n",
      "Epoch 26/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.7855 - acc: 0.3821 - val_loss: 1.7852 - val_acc: 0.3813\n",
      "Epoch 27/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.7803 - acc: 0.3842 - val_loss: 1.7808 - val_acc: 0.3836\n",
      "Epoch 28/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.7753 - acc: 0.3856 - val_loss: 1.7770 - val_acc: 0.3825\n",
      "Epoch 29/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.7705 - acc: 0.3881 - val_loss: 1.7718 - val_acc: 0.3853\n",
      "Epoch 30/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.7655 - acc: 0.3892 - val_loss: 1.7662 - val_acc: 0.3863\n",
      "Epoch 31/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.7607 - acc: 0.3900 - val_loss: 1.7630 - val_acc: 0.3919\n",
      "Epoch 32/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.7564 - acc: 0.3921 - val_loss: 1.7576 - val_acc: 0.3946\n",
      "Epoch 33/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.7518 - acc: 0.3943 - val_loss: 1.7537 - val_acc: 0.3939\n",
      "Epoch 34/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.7476 - acc: 0.3952 - val_loss: 1.7494 - val_acc: 0.3955\n",
      "Epoch 35/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.7434 - acc: 0.3967 - val_loss: 1.7472 - val_acc: 0.3976\n",
      "Epoch 36/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.7393 - acc: 0.3981 - val_loss: 1.7423 - val_acc: 0.3962\n",
      "Epoch 37/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.7353 - acc: 0.3988 - val_loss: 1.7376 - val_acc: 0.4011\n",
      "Epoch 38/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.7313 - acc: 0.4009 - val_loss: 1.7340 - val_acc: 0.4000\n",
      "Epoch 39/500\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.7275 - acc: 0.4023 - val_loss: 1.7308 - val_acc: 0.4046\n",
      "Epoch 40/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.7238 - acc: 0.4038 - val_loss: 1.7278 - val_acc: 0.4007\n",
      "Epoch 41/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.7203 - acc: 0.4048 - val_loss: 1.7227 - val_acc: 0.4016\n",
      "Epoch 42/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.7166 - acc: 0.4051 - val_loss: 1.7202 - val_acc: 0.4027\n",
      "Epoch 43/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.7130 - acc: 0.4074 - val_loss: 1.7178 - val_acc: 0.4006\n",
      "Epoch 44/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.7093 - acc: 0.4080 - val_loss: 1.7137 - val_acc: 0.4087\n",
      "Epoch 45/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.7061 - acc: 0.4096 - val_loss: 1.7106 - val_acc: 0.4097\n",
      "Epoch 46/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.7028 - acc: 0.4111 - val_loss: 1.7063 - val_acc: 0.4072\n",
      "Epoch 47/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.6995 - acc: 0.4121 - val_loss: 1.7034 - val_acc: 0.4102\n",
      "Epoch 48/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.6963 - acc: 0.4131 - val_loss: 1.7014 - val_acc: 0.4090\n",
      "Epoch 49/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.6932 - acc: 0.4132 - val_loss: 1.6972 - val_acc: 0.4122\n",
      "Epoch 50/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.6901 - acc: 0.4151 - val_loss: 1.6952 - val_acc: 0.4095\n",
      "Epoch 51/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.6870 - acc: 0.4160 - val_loss: 1.6923 - val_acc: 0.4093\n",
      "Epoch 52/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.6840 - acc: 0.4177 - val_loss: 1.6891 - val_acc: 0.4122\n",
      "Epoch 53/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.6812 - acc: 0.4186 - val_loss: 1.6872 - val_acc: 0.4127\n",
      "Epoch 54/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.6781 - acc: 0.4190 - val_loss: 1.6848 - val_acc: 0.4193\n",
      "Epoch 55/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.6754 - acc: 0.4198 - val_loss: 1.6817 - val_acc: 0.4163\n",
      "Epoch 56/500\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.6724 - acc: 0.4216 - val_loss: 1.6788 - val_acc: 0.4152\n",
      "Epoch 57/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.6695 - acc: 0.4224 - val_loss: 1.6759 - val_acc: 0.4185\n",
      "Epoch 58/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.6668 - acc: 0.4239 - val_loss: 1.6729 - val_acc: 0.4198\n",
      "Epoch 59/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.6642 - acc: 0.4252 - val_loss: 1.6712 - val_acc: 0.4215\n",
      "Epoch 60/500\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.6615 - acc: 0.4251 - val_loss: 1.6681 - val_acc: 0.4216\n",
      "Epoch 61/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.6587 - acc: 0.4273 - val_loss: 1.6662 - val_acc: 0.4215\n",
      "Epoch 62/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.6563 - acc: 0.4277 - val_loss: 1.6641 - val_acc: 0.4223\n",
      "Epoch 63/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.6534 - acc: 0.4288 - val_loss: 1.6621 - val_acc: 0.4240\n",
      "Epoch 64/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.6511 - acc: 0.4294 - val_loss: 1.6594 - val_acc: 0.4254\n",
      "Epoch 65/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.6485 - acc: 0.4305 - val_loss: 1.6560 - val_acc: 0.4275\n",
      "Epoch 66/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.6461 - acc: 0.4315 - val_loss: 1.6543 - val_acc: 0.4265\n",
      "Epoch 67/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.6436 - acc: 0.4321 - val_loss: 1.6520 - val_acc: 0.4251\n",
      "Epoch 68/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.6410 - acc: 0.4324 - val_loss: 1.6497 - val_acc: 0.4270\n",
      "Epoch 69/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.6386 - acc: 0.4341 - val_loss: 1.6478 - val_acc: 0.4263\n",
      "Epoch 70/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.6361 - acc: 0.4346 - val_loss: 1.6478 - val_acc: 0.4279\n",
      "Epoch 71/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.6338 - acc: 0.4354 - val_loss: 1.6440 - val_acc: 0.4269\n",
      "Epoch 72/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.6315 - acc: 0.4366 - val_loss: 1.6427 - val_acc: 0.4280\n",
      "Epoch 73/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.6293 - acc: 0.4370 - val_loss: 1.6388 - val_acc: 0.4287\n",
      "Epoch 74/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.6269 - acc: 0.4388 - val_loss: 1.6390 - val_acc: 0.4302\n",
      "Epoch 75/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.6246 - acc: 0.4392 - val_loss: 1.6358 - val_acc: 0.4302\n",
      "Epoch 76/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.6223 - acc: 0.4397 - val_loss: 1.6330 - val_acc: 0.4314\n",
      "Epoch 77/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.6202 - acc: 0.4410 - val_loss: 1.6325 - val_acc: 0.4355\n",
      "Epoch 78/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.6179 - acc: 0.4413 - val_loss: 1.6302 - val_acc: 0.4352\n",
      "Epoch 79/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.6157 - acc: 0.4422 - val_loss: 1.6273 - val_acc: 0.4340\n",
      "Epoch 80/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.6134 - acc: 0.4441 - val_loss: 1.6266 - val_acc: 0.4346\n",
      "Epoch 81/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.6115 - acc: 0.4435 - val_loss: 1.6234 - val_acc: 0.4360\n",
      "Epoch 82/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.6093 - acc: 0.4456 - val_loss: 1.6223 - val_acc: 0.4352\n",
      "Epoch 83/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.6072 - acc: 0.4456 - val_loss: 1.6209 - val_acc: 0.4361\n",
      "Epoch 84/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.6050 - acc: 0.4461 - val_loss: 1.6179 - val_acc: 0.4374\n",
      "Epoch 85/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.6032 - acc: 0.4472 - val_loss: 1.6169 - val_acc: 0.4394\n",
      "Epoch 86/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.6010 - acc: 0.4487 - val_loss: 1.6143 - val_acc: 0.4387\n",
      "Epoch 87/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.5989 - acc: 0.4498 - val_loss: 1.6135 - val_acc: 0.4385\n",
      "Epoch 88/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5973 - acc: 0.4488 - val_loss: 1.6110 - val_acc: 0.4401\n",
      "Epoch 89/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.5949 - acc: 0.4503 - val_loss: 1.6109 - val_acc: 0.4391\n",
      "Epoch 90/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.5930 - acc: 0.4512 - val_loss: 1.6084 - val_acc: 0.4414\n",
      "Epoch 91/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.5913 - acc: 0.4505 - val_loss: 1.6064 - val_acc: 0.4393\n",
      "Epoch 92/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.5893 - acc: 0.4524 - val_loss: 1.6049 - val_acc: 0.4403\n",
      "Epoch 93/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.5874 - acc: 0.4514 - val_loss: 1.6036 - val_acc: 0.4385\n",
      "Epoch 94/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.5855 - acc: 0.4525 - val_loss: 1.6007 - val_acc: 0.4425\n",
      "Epoch 95/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.5833 - acc: 0.4541 - val_loss: 1.5992 - val_acc: 0.4425\n",
      "Epoch 96/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.5816 - acc: 0.4533 - val_loss: 1.5982 - val_acc: 0.4439\n",
      "Epoch 97/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.5799 - acc: 0.4542 - val_loss: 1.5959 - val_acc: 0.4443\n",
      "Epoch 98/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.5779 - acc: 0.4554 - val_loss: 1.5971 - val_acc: 0.4434\n",
      "Epoch 99/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.5763 - acc: 0.4553 - val_loss: 1.5930 - val_acc: 0.4448\n",
      "Epoch 100/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.5745 - acc: 0.4569 - val_loss: 1.5915 - val_acc: 0.4456\n",
      "Epoch 101/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.5728 - acc: 0.4569 - val_loss: 1.5902 - val_acc: 0.4484\n",
      "Epoch 102/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.5709 - acc: 0.4580 - val_loss: 1.5884 - val_acc: 0.4483\n",
      "Epoch 103/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5691 - acc: 0.4569 - val_loss: 1.5877 - val_acc: 0.4460\n",
      "Epoch 104/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5673 - acc: 0.4579 - val_loss: 1.5866 - val_acc: 0.4467\n",
      "Epoch 105/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.5657 - acc: 0.4586 - val_loss: 1.5861 - val_acc: 0.4466\n",
      "Epoch 106/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5639 - acc: 0.4591 - val_loss: 1.5850 - val_acc: 0.4512\n",
      "Epoch 107/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5624 - acc: 0.4596 - val_loss: 1.5818 - val_acc: 0.4478\n",
      "Epoch 108/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5607 - acc: 0.4608 - val_loss: 1.5811 - val_acc: 0.4488\n",
      "Epoch 109/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5589 - acc: 0.4604 - val_loss: 1.5788 - val_acc: 0.4509\n",
      "Epoch 110/500\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.5572 - acc: 0.4621 - val_loss: 1.5780 - val_acc: 0.4495\n",
      "Epoch 111/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.5555 - acc: 0.4621 - val_loss: 1.5806 - val_acc: 0.4433\n",
      "Epoch 112/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5538 - acc: 0.4625 - val_loss: 1.5770 - val_acc: 0.4517\n",
      "Epoch 113/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.5524 - acc: 0.4632 - val_loss: 1.5737 - val_acc: 0.4524\n",
      "Epoch 114/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.5505 - acc: 0.4635 - val_loss: 1.5744 - val_acc: 0.4488\n",
      "Epoch 115/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5492 - acc: 0.4636 - val_loss: 1.5717 - val_acc: 0.4516\n",
      "Epoch 116/500\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.5475 - acc: 0.4644 - val_loss: 1.5705 - val_acc: 0.4504\n",
      "Epoch 117/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5460 - acc: 0.4648 - val_loss: 1.5682 - val_acc: 0.4584\n",
      "Epoch 118/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.5443 - acc: 0.4652 - val_loss: 1.5669 - val_acc: 0.4543\n",
      "Epoch 119/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5427 - acc: 0.4661 - val_loss: 1.5675 - val_acc: 0.4537\n",
      "Epoch 120/500\n",
      "50000/50000 [==============================] - 6s 122us/step - loss: 1.5410 - acc: 0.4665 - val_loss: 1.5651 - val_acc: 0.4548\n",
      "Epoch 121/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5396 - acc: 0.4662 - val_loss: 1.5643 - val_acc: 0.4527\n",
      "Epoch 122/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.5382 - acc: 0.4672 - val_loss: 1.5626 - val_acc: 0.4524\n",
      "Epoch 123/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.5366 - acc: 0.4683 - val_loss: 1.5642 - val_acc: 0.4564\n",
      "Epoch 124/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.5350 - acc: 0.4691 - val_loss: 1.5609 - val_acc: 0.4557\n",
      "Epoch 125/500\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.5334 - acc: 0.4691 - val_loss: 1.5604 - val_acc: 0.4535\n",
      "Epoch 126/500\n",
      "50000/50000 [==============================] - 8s 163us/step - loss: 1.5320 - acc: 0.4700 - val_loss: 1.5568 - val_acc: 0.4588\n",
      "Epoch 127/500\n",
      "50000/50000 [==============================] - 8s 151us/step - loss: 1.5306 - acc: 0.4697 - val_loss: 1.5581 - val_acc: 0.4567\n",
      "Epoch 128/500\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.5289 - acc: 0.4708 - val_loss: 1.5561 - val_acc: 0.4562\n",
      "Epoch 129/500\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.5277 - acc: 0.4701 - val_loss: 1.5558 - val_acc: 0.4555\n",
      "Epoch 130/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.5261 - acc: 0.4712 - val_loss: 1.5520 - val_acc: 0.4585\n",
      "Epoch 131/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.5247 - acc: 0.4712 - val_loss: 1.5522 - val_acc: 0.4559\n",
      "Epoch 132/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.5234 - acc: 0.4732 - val_loss: 1.5501 - val_acc: 0.4595\n",
      "Epoch 133/500\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.5220 - acc: 0.4717 - val_loss: 1.5512 - val_acc: 0.4562\n",
      "Epoch 134/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.5204 - acc: 0.4733 - val_loss: 1.5500 - val_acc: 0.4590\n",
      "Epoch 135/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.5190 - acc: 0.4744 - val_loss: 1.5484 - val_acc: 0.4582\n",
      "Epoch 136/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.5179 - acc: 0.4738 - val_loss: 1.5476 - val_acc: 0.4598\n",
      "Epoch 137/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.5163 - acc: 0.4754 - val_loss: 1.5448 - val_acc: 0.4596\n",
      "Epoch 138/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.5148 - acc: 0.4753 - val_loss: 1.5441 - val_acc: 0.4618\n",
      "Epoch 139/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.5134 - acc: 0.4757 - val_loss: 1.5429 - val_acc: 0.4599\n",
      "Epoch 140/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.5120 - acc: 0.4764 - val_loss: 1.5424 - val_acc: 0.4633\n",
      "Epoch 141/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.5104 - acc: 0.4772 - val_loss: 1.5428 - val_acc: 0.4561\n",
      "Epoch 142/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.5093 - acc: 0.4761 - val_loss: 1.5399 - val_acc: 0.4622\n",
      "Epoch 143/500\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.5080 - acc: 0.4784 - val_loss: 1.5409 - val_acc: 0.4635\n",
      "Epoch 144/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.5066 - acc: 0.4783 - val_loss: 1.5385 - val_acc: 0.4620\n",
      "Epoch 145/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.5052 - acc: 0.4795 - val_loss: 1.5359 - val_acc: 0.4635\n",
      "Epoch 146/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.5040 - acc: 0.4785 - val_loss: 1.5371 - val_acc: 0.4606\n",
      "Epoch 147/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.5027 - acc: 0.4800 - val_loss: 1.5353 - val_acc: 0.4637\n",
      "Epoch 148/500\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.5013 - acc: 0.4803 - val_loss: 1.5335 - val_acc: 0.4591\n",
      "Epoch 149/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.4998 - acc: 0.4812 - val_loss: 1.5334 - val_acc: 0.4647\n",
      "Epoch 150/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.4988 - acc: 0.4810 - val_loss: 1.5349 - val_acc: 0.4628\n",
      "Epoch 151/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.4973 - acc: 0.4814 - val_loss: 1.5302 - val_acc: 0.4625\n",
      "Epoch 152/500\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.4961 - acc: 0.4819 - val_loss: 1.5291 - val_acc: 0.4628\n",
      "Epoch 153/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.4948 - acc: 0.4818 - val_loss: 1.5279 - val_acc: 0.4655\n",
      "Epoch 154/500\n",
      "50000/50000 [==============================] - 7s 143us/step - loss: 1.4936 - acc: 0.4826 - val_loss: 1.5289 - val_acc: 0.4663\n",
      "Epoch 155/500\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.4923 - acc: 0.4832 - val_loss: 1.5277 - val_acc: 0.4640\n",
      "Epoch 156/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.4909 - acc: 0.4832 - val_loss: 1.5260 - val_acc: 0.4642\n",
      "Epoch 157/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.4897 - acc: 0.4842 - val_loss: 1.5279 - val_acc: 0.4666\n",
      "Epoch 158/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.4885 - acc: 0.4846 - val_loss: 1.5253 - val_acc: 0.4670\n",
      "Epoch 159/500\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.4872 - acc: 0.4847 - val_loss: 1.5249 - val_acc: 0.4624\n",
      "Epoch 160/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.4858 - acc: 0.4858 - val_loss: 1.5234 - val_acc: 0.4644\n",
      "Epoch 161/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.4847 - acc: 0.4852 - val_loss: 1.5215 - val_acc: 0.4663\n",
      "Epoch 162/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.4834 - acc: 0.4861 - val_loss: 1.5199 - val_acc: 0.4667\n",
      "Epoch 163/500\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 1.4822 - acc: 0.4871 - val_loss: 1.5196 - val_acc: 0.4638\n",
      "Epoch 164/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.4811 - acc: 0.4875 - val_loss: 1.5182 - val_acc: 0.4678\n",
      "Epoch 165/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.4797 - acc: 0.4869 - val_loss: 1.5184 - val_acc: 0.4663\n",
      "Epoch 166/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.4786 - acc: 0.4877 - val_loss: 1.5167 - val_acc: 0.4668\n",
      "Epoch 167/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.4772 - acc: 0.4887 - val_loss: 1.5174 - val_acc: 0.4709\n",
      "Epoch 168/500\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 1.4760 - acc: 0.4901 - val_loss: 1.5145 - val_acc: 0.4666\n",
      "Epoch 169/500\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 1.4749 - acc: 0.4896 - val_loss: 1.5149 - val_acc: 0.4702\n",
      "Epoch 170/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.4737 - acc: 0.4902 - val_loss: 1.5132 - val_acc: 0.4717\n",
      "Epoch 171/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.4722 - acc: 0.4911 - val_loss: 1.5129 - val_acc: 0.4680\n",
      "Epoch 172/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.4713 - acc: 0.4900 - val_loss: 1.5125 - val_acc: 0.4706\n",
      "Epoch 173/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.4699 - acc: 0.4926 - val_loss: 1.5137 - val_acc: 0.4668\n",
      "Epoch 174/500\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 1.4690 - acc: 0.4914 - val_loss: 1.5086 - val_acc: 0.4703\n",
      "Epoch 175/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.4675 - acc: 0.4915 - val_loss: 1.5071 - val_acc: 0.4721\n",
      "Epoch 176/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.4663 - acc: 0.4932 - val_loss: 1.5089 - val_acc: 0.4713\n",
      "Epoch 177/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.4654 - acc: 0.4921 - val_loss: 1.5078 - val_acc: 0.4699\n",
      "Epoch 178/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.4642 - acc: 0.4935 - val_loss: 1.5059 - val_acc: 0.4716\n",
      "Epoch 179/500\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.4630 - acc: 0.4940 - val_loss: 1.5057 - val_acc: 0.4755\n",
      "Epoch 180/500\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 1.4617 - acc: 0.4936 - val_loss: 1.5055 - val_acc: 0.4748\n",
      "Epoch 181/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.4606 - acc: 0.4943 - val_loss: 1.5029 - val_acc: 0.4736\n",
      "Epoch 182/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.4594 - acc: 0.4951 - val_loss: 1.5068 - val_acc: 0.4703\n",
      "Epoch 183/500\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 1.4586 - acc: 0.4942 - val_loss: 1.5023 - val_acc: 0.4756\n",
      "Epoch 184/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.4573 - acc: 0.4949 - val_loss: 1.5006 - val_acc: 0.4733\n",
      "Epoch 185/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.4561 - acc: 0.4961 - val_loss: 1.4999 - val_acc: 0.4741\n",
      "Epoch 186/500\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 1.4549 - acc: 0.4961 - val_loss: 1.4992 - val_acc: 0.4745\n",
      "Epoch 187/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.4538 - acc: 0.4969 - val_loss: 1.4969 - val_acc: 0.4771\n",
      "Epoch 188/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.4525 - acc: 0.4967 - val_loss: 1.4978 - val_acc: 0.4760\n",
      "Epoch 189/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.4515 - acc: 0.4978 - val_loss: 1.4984 - val_acc: 0.4742\n",
      "Epoch 190/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.4503 - acc: 0.4997 - val_loss: 1.4980 - val_acc: 0.4721\n",
      "Epoch 191/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.4493 - acc: 0.4976 - val_loss: 1.4947 - val_acc: 0.4736\n",
      "Epoch 192/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.4481 - acc: 0.4991 - val_loss: 1.4934 - val_acc: 0.4750\n",
      "Epoch 193/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.4471 - acc: 0.4995 - val_loss: 1.4930 - val_acc: 0.4751\n",
      "Epoch 194/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.4455 - acc: 0.5003 - val_loss: 1.4938 - val_acc: 0.4781\n",
      "Epoch 195/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.4449 - acc: 0.5011 - val_loss: 1.4940 - val_acc: 0.4793\n",
      "Epoch 196/500\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.4436 - acc: 0.5000 - val_loss: 1.4932 - val_acc: 0.4755\n",
      "Epoch 197/500\n",
      "50000/50000 [==============================] - 7s 137us/step - loss: 1.4427 - acc: 0.5007 - val_loss: 1.4892 - val_acc: 0.4752\n",
      "Epoch 198/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.4412 - acc: 0.5012 - val_loss: 1.4929 - val_acc: 0.4737\n",
      "Epoch 199/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.4402 - acc: 0.5019 - val_loss: 1.4883 - val_acc: 0.4800\n",
      "Epoch 200/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.4393 - acc: 0.5019 - val_loss: 1.4866 - val_acc: 0.4792\n",
      "Epoch 201/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.4379 - acc: 0.5017 - val_loss: 1.4877 - val_acc: 0.4795\n",
      "Epoch 202/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.4372 - acc: 0.5026 - val_loss: 1.4878 - val_acc: 0.4762\n",
      "Epoch 203/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.4358 - acc: 0.5044 - val_loss: 1.4852 - val_acc: 0.4827\n",
      "Epoch 204/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.4347 - acc: 0.5032 - val_loss: 1.4839 - val_acc: 0.4797\n",
      "Epoch 205/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.4337 - acc: 0.5035 - val_loss: 1.4834 - val_acc: 0.4843\n",
      "Epoch 206/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.4325 - acc: 0.5049 - val_loss: 1.4845 - val_acc: 0.4807\n",
      "Epoch 207/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.4317 - acc: 0.5045 - val_loss: 1.4830 - val_acc: 0.4807\n",
      "Epoch 208/500\n",
      "50000/50000 [==============================] - 7s 149us/step - loss: 1.4302 - acc: 0.5052 - val_loss: 1.4817 - val_acc: 0.4802\n",
      "Epoch 209/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.4293 - acc: 0.5065 - val_loss: 1.4818 - val_acc: 0.4830\n",
      "Epoch 210/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.4283 - acc: 0.5057 - val_loss: 1.4828 - val_acc: 0.4777\n",
      "Epoch 211/500\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.4273 - acc: 0.5065 - val_loss: 1.4806 - val_acc: 0.4800\n",
      "Epoch 212/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.4262 - acc: 0.5066 - val_loss: 1.4791 - val_acc: 0.4790\n",
      "Epoch 213/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.4251 - acc: 0.5066 - val_loss: 1.4793 - val_acc: 0.4835\n",
      "Epoch 214/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.4239 - acc: 0.5077 - val_loss: 1.4760 - val_acc: 0.4856\n",
      "Epoch 215/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.4230 - acc: 0.5083 - val_loss: 1.4765 - val_acc: 0.4828\n",
      "Epoch 216/500\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.4220 - acc: 0.5082 - val_loss: 1.4747 - val_acc: 0.4839\n",
      "Epoch 217/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.4207 - acc: 0.5082 - val_loss: 1.4763 - val_acc: 0.4869\n",
      "Epoch 218/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.4200 - acc: 0.5088 - val_loss: 1.4748 - val_acc: 0.4803\n",
      "Epoch 219/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.4185 - acc: 0.5095 - val_loss: 1.4726 - val_acc: 0.4837\n",
      "Epoch 220/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.4175 - acc: 0.5100 - val_loss: 1.4721 - val_acc: 0.4844\n",
      "Epoch 221/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.4166 - acc: 0.5104 - val_loss: 1.4714 - val_acc: 0.4828\n",
      "Epoch 222/500\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 1.4154 - acc: 0.5102 - val_loss: 1.4710 - val_acc: 0.4851\n",
      "Epoch 223/500\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 1.4146 - acc: 0.5117 - val_loss: 1.4707 - val_acc: 0.4807\n",
      "Epoch 224/500\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 1.4133 - acc: 0.5106 - val_loss: 1.4697 - val_acc: 0.4847\n",
      "Epoch 225/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.4123 - acc: 0.5115 - val_loss: 1.4697 - val_acc: 0.4838\n",
      "Epoch 226/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.4112 - acc: 0.5117 - val_loss: 1.4694 - val_acc: 0.4852\n",
      "Epoch 227/500\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 1.4104 - acc: 0.5124 - val_loss: 1.4670 - val_acc: 0.4850\n",
      "Epoch 228/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.4092 - acc: 0.5129 - val_loss: 1.4670 - val_acc: 0.4886\n",
      "Epoch 229/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.4082 - acc: 0.5130 - val_loss: 1.4661 - val_acc: 0.4853\n",
      "Epoch 230/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.4071 - acc: 0.5130 - val_loss: 1.4654 - val_acc: 0.4834\n",
      "Epoch 231/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.4061 - acc: 0.5135 - val_loss: 1.4665 - val_acc: 0.4837\n",
      "Epoch 232/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.4052 - acc: 0.5147 - val_loss: 1.4642 - val_acc: 0.4872\n",
      "Epoch 233/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.4041 - acc: 0.5141 - val_loss: 1.4629 - val_acc: 0.4853\n",
      "Epoch 234/500\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 1.4027 - acc: 0.5158 - val_loss: 1.4618 - val_acc: 0.4857\n",
      "Epoch 235/500\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 1.4020 - acc: 0.5152 - val_loss: 1.4610 - val_acc: 0.4890\n",
      "Epoch 236/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.4012 - acc: 0.5157 - val_loss: 1.4601 - val_acc: 0.4896\n",
      "Epoch 237/500\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 1.4001 - acc: 0.5149 - val_loss: 1.4613 - val_acc: 0.4908\n",
      "Epoch 238/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.3990 - acc: 0.5167 - val_loss: 1.4622 - val_acc: 0.4898\n",
      "Epoch 239/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.3979 - acc: 0.5175 - val_loss: 1.4580 - val_acc: 0.4892\n",
      "Epoch 240/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.3968 - acc: 0.5165 - val_loss: 1.4613 - val_acc: 0.4824\n",
      "Epoch 241/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.3960 - acc: 0.5180 - val_loss: 1.4567 - val_acc: 0.4879\n",
      "Epoch 242/500\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 1.3949 - acc: 0.5174 - val_loss: 1.4565 - val_acc: 0.4899\n",
      "Epoch 243/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.3936 - acc: 0.5187 - val_loss: 1.4577 - val_acc: 0.4920\n",
      "Epoch 244/500\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 1.3929 - acc: 0.5185 - val_loss: 1.4570 - val_acc: 0.4849\n",
      "Epoch 245/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.3919 - acc: 0.5193 - val_loss: 1.4554 - val_acc: 0.4903\n",
      "Epoch 246/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.3908 - acc: 0.5184 - val_loss: 1.4584 - val_acc: 0.4894\n",
      "Epoch 247/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.3899 - acc: 0.5203 - val_loss: 1.4531 - val_acc: 0.4875\n",
      "Epoch 248/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.3887 - acc: 0.5186 - val_loss: 1.4518 - val_acc: 0.4880\n",
      "Epoch 249/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.3878 - acc: 0.5202 - val_loss: 1.4538 - val_acc: 0.4924\n",
      "Epoch 250/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.3867 - acc: 0.5207 - val_loss: 1.4500 - val_acc: 0.4898\n",
      "Epoch 251/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.3860 - acc: 0.5198 - val_loss: 1.4514 - val_acc: 0.4893\n",
      "Epoch 252/500\n",
      "50000/50000 [==============================] - 7s 139us/step - loss: 1.3847 - acc: 0.5214 - val_loss: 1.4505 - val_acc: 0.4879\n",
      "Epoch 253/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.3839 - acc: 0.5212 - val_loss: 1.4517 - val_acc: 0.4866\n",
      "Epoch 254/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.3828 - acc: 0.5221 - val_loss: 1.4478 - val_acc: 0.4944\n",
      "Epoch 255/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.3819 - acc: 0.5232 - val_loss: 1.4475 - val_acc: 0.4902\n",
      "Epoch 256/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.3812 - acc: 0.5231 - val_loss: 1.4476 - val_acc: 0.4894\n",
      "Epoch 257/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.3796 - acc: 0.5226 - val_loss: 1.4467 - val_acc: 0.4905\n",
      "Epoch 258/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.3790 - acc: 0.5237 - val_loss: 1.4455 - val_acc: 0.4919\n",
      "Epoch 259/500\n",
      "50000/50000 [==============================] - 7s 134us/step - loss: 1.3778 - acc: 0.5242 - val_loss: 1.4471 - val_acc: 0.4880\n",
      "Epoch 260/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.3771 - acc: 0.5242 - val_loss: 1.4473 - val_acc: 0.4930\n",
      "Epoch 261/500\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 1.3761 - acc: 0.5249 - val_loss: 1.4450 - val_acc: 0.4911\n",
      "Epoch 262/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.3748 - acc: 0.5260 - val_loss: 1.4447 - val_acc: 0.4908\n",
      "Epoch 263/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.3739 - acc: 0.5237 - val_loss: 1.4437 - val_acc: 0.4918\n",
      "Epoch 264/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.3730 - acc: 0.5267 - val_loss: 1.4410 - val_acc: 0.4933\n",
      "Epoch 265/500\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 1.3719 - acc: 0.5263 - val_loss: 1.4439 - val_acc: 0.4864\n",
      "Epoch 266/500\n",
      "50000/50000 [==============================] - 7s 138us/step - loss: 1.3709 - acc: 0.5276 - val_loss: 1.4407 - val_acc: 0.4937\n",
      "Epoch 267/500\n",
      "50000/50000 [==============================] - 8s 167us/step - loss: 1.3700 - acc: 0.5274 - val_loss: 1.4411 - val_acc: 0.4921\n",
      "Epoch 268/500\n",
      "50000/50000 [==============================] - 8s 158us/step - loss: 1.3691 - acc: 0.5276 - val_loss: 1.4412 - val_acc: 0.4931\n",
      "Epoch 269/500\n",
      "50000/50000 [==============================] - 8s 161us/step - loss: 1.3682 - acc: 0.5260 - val_loss: 1.4414 - val_acc: 0.4929\n",
      "Epoch 270/500\n",
      "50000/50000 [==============================] - 8s 166us/step - loss: 1.3673 - acc: 0.5270 - val_loss: 1.4391 - val_acc: 0.4916\n",
      "Epoch 271/500\n",
      "50000/50000 [==============================] - 7s 141us/step - loss: 1.3663 - acc: 0.5286 - val_loss: 1.4387 - val_acc: 0.4960\n",
      "Epoch 272/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.3655 - acc: 0.5289 - val_loss: 1.4394 - val_acc: 0.4919\n",
      "Epoch 273/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3645 - acc: 0.5292 - val_loss: 1.4382 - val_acc: 0.4922\n",
      "Epoch 274/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.3632 - acc: 0.5288 - val_loss: 1.4378 - val_acc: 0.4926\n",
      "Epoch 275/500\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 1.3626 - acc: 0.5296 - val_loss: 1.4360 - val_acc: 0.4934\n",
      "Epoch 276/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.3613 - acc: 0.5303 - val_loss: 1.4390 - val_acc: 0.4920\n",
      "Epoch 277/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3606 - acc: 0.5307 - val_loss: 1.4405 - val_acc: 0.4881\n",
      "Epoch 278/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3598 - acc: 0.5305 - val_loss: 1.4329 - val_acc: 0.4942\n",
      "Epoch 279/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3585 - acc: 0.5308 - val_loss: 1.4370 - val_acc: 0.4920\n",
      "Epoch 280/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3579 - acc: 0.5317 - val_loss: 1.4341 - val_acc: 0.4943\n",
      "Epoch 281/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3568 - acc: 0.5318 - val_loss: 1.4329 - val_acc: 0.4936\n",
      "Epoch 282/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3559 - acc: 0.5316 - val_loss: 1.4325 - val_acc: 0.4952\n",
      "Epoch 283/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.3550 - acc: 0.5325 - val_loss: 1.4301 - val_acc: 0.4957\n",
      "Epoch 284/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3541 - acc: 0.5331 - val_loss: 1.4314 - val_acc: 0.4963\n",
      "Epoch 285/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.3529 - acc: 0.5336 - val_loss: 1.4297 - val_acc: 0.4983\n",
      "Epoch 286/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3525 - acc: 0.5328 - val_loss: 1.4335 - val_acc: 0.4955\n",
      "Epoch 287/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3508 - acc: 0.5334 - val_loss: 1.4295 - val_acc: 0.4988\n",
      "Epoch 288/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.3501 - acc: 0.5336 - val_loss: 1.4316 - val_acc: 0.4966\n",
      "Epoch 289/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3493 - acc: 0.5351 - val_loss: 1.4270 - val_acc: 0.4966\n",
      "Epoch 290/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3487 - acc: 0.5357 - val_loss: 1.4298 - val_acc: 0.4963\n",
      "Epoch 291/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.3472 - acc: 0.5363 - val_loss: 1.4281 - val_acc: 0.4971\n",
      "Epoch 292/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3466 - acc: 0.5358 - val_loss: 1.4268 - val_acc: 0.4970\n",
      "Epoch 293/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3456 - acc: 0.5358 - val_loss: 1.4269 - val_acc: 0.4993\n",
      "Epoch 294/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3446 - acc: 0.5360 - val_loss: 1.4283 - val_acc: 0.4932\n",
      "Epoch 295/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3439 - acc: 0.5368 - val_loss: 1.4253 - val_acc: 0.4972\n",
      "Epoch 296/500\n",
      "50000/50000 [==============================] - 6s 124us/step - loss: 1.3427 - acc: 0.5356 - val_loss: 1.4233 - val_acc: 0.4989\n",
      "Epoch 297/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.3419 - acc: 0.5370 - val_loss: 1.4251 - val_acc: 0.4963\n",
      "Epoch 298/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.3412 - acc: 0.5371 - val_loss: 1.4234 - val_acc: 0.4968\n",
      "Epoch 299/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.3401 - acc: 0.5364 - val_loss: 1.4246 - val_acc: 0.4976\n",
      "Epoch 300/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.3394 - acc: 0.5386 - val_loss: 1.4246 - val_acc: 0.4957\n",
      "Epoch 301/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3385 - acc: 0.5375 - val_loss: 1.4227 - val_acc: 0.4990\n",
      "Epoch 302/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3375 - acc: 0.5387 - val_loss: 1.4211 - val_acc: 0.5011\n",
      "Epoch 303/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3369 - acc: 0.5381 - val_loss: 1.4227 - val_acc: 0.4950\n",
      "Epoch 304/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3355 - acc: 0.5388 - val_loss: 1.4238 - val_acc: 0.4960\n",
      "Epoch 305/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3349 - acc: 0.5387 - val_loss: 1.4190 - val_acc: 0.5022\n",
      "Epoch 306/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3341 - acc: 0.5403 - val_loss: 1.4284 - val_acc: 0.4928\n",
      "Epoch 307/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3330 - acc: 0.5389 - val_loss: 1.4194 - val_acc: 0.4981\n",
      "Epoch 308/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3323 - acc: 0.5408 - val_loss: 1.4166 - val_acc: 0.5001\n",
      "Epoch 309/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3312 - acc: 0.5400 - val_loss: 1.4157 - val_acc: 0.4991\n",
      "Epoch 310/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3304 - acc: 0.5407 - val_loss: 1.4178 - val_acc: 0.4995\n",
      "Epoch 311/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3293 - acc: 0.5410 - val_loss: 1.4225 - val_acc: 0.4979\n",
      "Epoch 312/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3285 - acc: 0.5416 - val_loss: 1.4146 - val_acc: 0.5018\n",
      "Epoch 313/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3274 - acc: 0.5416 - val_loss: 1.4199 - val_acc: 0.4936\n",
      "Epoch 314/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3268 - acc: 0.5426 - val_loss: 1.4141 - val_acc: 0.5024\n",
      "Epoch 315/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3259 - acc: 0.5425 - val_loss: 1.4145 - val_acc: 0.4983\n",
      "Epoch 316/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.3250 - acc: 0.5427 - val_loss: 1.4150 - val_acc: 0.4988\n",
      "Epoch 317/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3240 - acc: 0.5430 - val_loss: 1.4157 - val_acc: 0.5005\n",
      "Epoch 318/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3233 - acc: 0.5429 - val_loss: 1.4135 - val_acc: 0.5031\n",
      "Epoch 319/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3225 - acc: 0.5434 - val_loss: 1.4122 - val_acc: 0.5040\n",
      "Epoch 320/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.3215 - acc: 0.5437 - val_loss: 1.4140 - val_acc: 0.4998\n",
      "Epoch 321/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3205 - acc: 0.5443 - val_loss: 1.4108 - val_acc: 0.5026\n",
      "Epoch 322/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.3194 - acc: 0.5450 - val_loss: 1.4102 - val_acc: 0.5018\n",
      "Epoch 323/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.3186 - acc: 0.5453 - val_loss: 1.4174 - val_acc: 0.5006\n",
      "Epoch 324/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3179 - acc: 0.5458 - val_loss: 1.4113 - val_acc: 0.4980\n",
      "Epoch 325/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3170 - acc: 0.5461 - val_loss: 1.4089 - val_acc: 0.5036\n",
      "Epoch 326/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.3159 - acc: 0.5459 - val_loss: 1.4087 - val_acc: 0.5008\n",
      "Epoch 327/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3154 - acc: 0.5454 - val_loss: 1.4119 - val_acc: 0.5017\n",
      "Epoch 328/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3140 - acc: 0.5467 - val_loss: 1.4134 - val_acc: 0.4995\n",
      "Epoch 329/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3137 - acc: 0.5471 - val_loss: 1.4067 - val_acc: 0.5034\n",
      "Epoch 330/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3127 - acc: 0.5481 - val_loss: 1.4092 - val_acc: 0.5041\n",
      "Epoch 331/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3116 - acc: 0.5475 - val_loss: 1.4048 - val_acc: 0.5044\n",
      "Epoch 332/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3112 - acc: 0.5469 - val_loss: 1.4083 - val_acc: 0.5028\n",
      "Epoch 333/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3104 - acc: 0.5483 - val_loss: 1.4030 - val_acc: 0.5030\n",
      "Epoch 334/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3092 - acc: 0.5487 - val_loss: 1.4065 - val_acc: 0.5023\n",
      "Epoch 335/500\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.3084 - acc: 0.5480 - val_loss: 1.4065 - val_acc: 0.5022\n",
      "Epoch 336/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3076 - acc: 0.5492 - val_loss: 1.4051 - val_acc: 0.5038\n",
      "Epoch 337/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3069 - acc: 0.5492 - val_loss: 1.4043 - val_acc: 0.5021\n",
      "Epoch 338/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.3053 - acc: 0.5509 - val_loss: 1.4038 - val_acc: 0.5046\n",
      "Epoch 339/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3047 - acc: 0.5502 - val_loss: 1.4015 - val_acc: 0.5039\n",
      "Epoch 340/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3041 - acc: 0.5506 - val_loss: 1.4053 - val_acc: 0.5039\n",
      "Epoch 341/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.3035 - acc: 0.5504 - val_loss: 1.4040 - val_acc: 0.5050\n",
      "Epoch 342/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.3025 - acc: 0.5515 - val_loss: 1.4003 - val_acc: 0.5042\n",
      "Epoch 343/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.3016 - acc: 0.5516 - val_loss: 1.4002 - val_acc: 0.5039\n",
      "Epoch 344/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.3008 - acc: 0.5515 - val_loss: 1.4011 - val_acc: 0.5039\n",
      "Epoch 345/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.2996 - acc: 0.5510 - val_loss: 1.3983 - val_acc: 0.5078\n",
      "Epoch 346/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.2989 - acc: 0.5524 - val_loss: 1.3998 - val_acc: 0.5033\n",
      "Epoch 347/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.2980 - acc: 0.5530 - val_loss: 1.3985 - val_acc: 0.5038\n",
      "Epoch 348/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.2977 - acc: 0.5527 - val_loss: 1.3989 - val_acc: 0.5036\n",
      "Epoch 349/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.2967 - acc: 0.5529 - val_loss: 1.3974 - val_acc: 0.5051\n",
      "Epoch 350/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.2959 - acc: 0.5535 - val_loss: 1.3990 - val_acc: 0.5047\n",
      "Epoch 351/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.2947 - acc: 0.5541 - val_loss: 1.3954 - val_acc: 0.5072\n",
      "Epoch 352/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.2937 - acc: 0.5533 - val_loss: 1.3960 - val_acc: 0.5079\n",
      "Epoch 353/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.2928 - acc: 0.5549 - val_loss: 1.3964 - val_acc: 0.5036\n",
      "Epoch 354/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.2922 - acc: 0.5541 - val_loss: 1.3951 - val_acc: 0.5066\n",
      "Epoch 355/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.2912 - acc: 0.5550 - val_loss: 1.3940 - val_acc: 0.5090\n",
      "Epoch 356/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.2906 - acc: 0.5552 - val_loss: 1.3942 - val_acc: 0.5071\n",
      "Epoch 357/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.2894 - acc: 0.5536 - val_loss: 1.3947 - val_acc: 0.5067\n",
      "Epoch 358/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.2892 - acc: 0.5557 - val_loss: 1.3937 - val_acc: 0.5083\n",
      "Epoch 359/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.2884 - acc: 0.5562 - val_loss: 1.3965 - val_acc: 0.5071\n",
      "Epoch 360/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.2875 - acc: 0.5560 - val_loss: 1.3958 - val_acc: 0.5044\n",
      "Epoch 361/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.2866 - acc: 0.5560 - val_loss: 1.3931 - val_acc: 0.5079\n",
      "Epoch 362/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.2860 - acc: 0.5571 - val_loss: 1.4027 - val_acc: 0.5000\n",
      "Epoch 363/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.2849 - acc: 0.5574 - val_loss: 1.3902 - val_acc: 0.5095\n",
      "Epoch 364/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.2840 - acc: 0.5563 - val_loss: 1.3942 - val_acc: 0.5097\n",
      "Epoch 365/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.2830 - acc: 0.5581 - val_loss: 1.3910 - val_acc: 0.5072\n",
      "Epoch 366/500\n",
      "50000/50000 [==============================] - 6s 125us/step - loss: 1.2824 - acc: 0.5582 - val_loss: 1.3929 - val_acc: 0.5055\n",
      "Epoch 367/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.2815 - acc: 0.5585 - val_loss: 1.3899 - val_acc: 0.5073\n",
      "Epoch 368/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.2805 - acc: 0.5577 - val_loss: 1.3917 - val_acc: 0.5061\n",
      "Epoch 369/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.2800 - acc: 0.5588 - val_loss: 1.3899 - val_acc: 0.5094\n",
      "Epoch 370/500\n",
      "50000/50000 [==============================] - 6s 130us/step - loss: 1.2794 - acc: 0.5590 - val_loss: 1.3903 - val_acc: 0.5048\n",
      "Epoch 371/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.2785 - acc: 0.5590 - val_loss: 1.3899 - val_acc: 0.5091\n",
      "Epoch 372/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.2775 - acc: 0.5590 - val_loss: 1.3875 - val_acc: 0.5090\n",
      "Epoch 373/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.2768 - acc: 0.5595 - val_loss: 1.3878 - val_acc: 0.5098\n",
      "Epoch 374/500\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.2759 - acc: 0.5588 - val_loss: 1.3901 - val_acc: 0.5076\n",
      "Epoch 375/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.2752 - acc: 0.5600 - val_loss: 1.3922 - val_acc: 0.5086\n",
      "Epoch 376/500\n",
      "50000/50000 [==============================] - 7s 132us/step - loss: 1.2745 - acc: 0.5603 - val_loss: 1.3896 - val_acc: 0.5063\n",
      "Epoch 377/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.2730 - acc: 0.5615 - val_loss: 1.3839 - val_acc: 0.5111\n",
      "Epoch 378/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.2725 - acc: 0.5621 - val_loss: 1.3861 - val_acc: 0.5119\n",
      "Epoch 379/500\n",
      "50000/50000 [==============================] - 6s 126us/step - loss: 1.2718 - acc: 0.5618 - val_loss: 1.3869 - val_acc: 0.5075\n",
      "Epoch 380/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.2712 - acc: 0.5615 - val_loss: 1.3868 - val_acc: 0.5082\n",
      "Epoch 381/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.2702 - acc: 0.5614 - val_loss: 1.3873 - val_acc: 0.5102\n",
      "Epoch 382/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.2697 - acc: 0.5619 - val_loss: 1.3820 - val_acc: 0.5105\n",
      "Epoch 383/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.2686 - acc: 0.5630 - val_loss: 1.3849 - val_acc: 0.5085\n",
      "Epoch 384/500\n",
      "50000/50000 [==============================] - 7s 130us/step - loss: 1.2679 - acc: 0.5631 - val_loss: 1.3850 - val_acc: 0.5092\n",
      "Epoch 385/500\n",
      "50000/50000 [==============================] - 6s 123us/step - loss: 1.2670 - acc: 0.5639 - val_loss: 1.3872 - val_acc: 0.5048\n",
      "Epoch 386/500\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.2661 - acc: 0.5636 - val_loss: 1.3823 - val_acc: 0.5126\n",
      "Epoch 387/500\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.2657 - acc: 0.5635 - val_loss: 1.3858 - val_acc: 0.5096\n",
      "Epoch 388/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.2645 - acc: 0.5641 - val_loss: 1.3823 - val_acc: 0.5107\n",
      "Epoch 389/500\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.2638 - acc: 0.5646 - val_loss: 1.3852 - val_acc: 0.5070\n",
      "Epoch 390/500\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.2632 - acc: 0.5635 - val_loss: 1.3819 - val_acc: 0.5113\n",
      "Epoch 391/500\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.2625 - acc: 0.5649 - val_loss: 1.3798 - val_acc: 0.5111\n",
      "Epoch 392/500\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.2617 - acc: 0.5667 - val_loss: 1.3811 - val_acc: 0.5099\n",
      "Epoch 393/500\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.2608 - acc: 0.5659 - val_loss: 1.3831 - val_acc: 0.5131\n",
      "Epoch 394/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.2603 - acc: 0.5660 - val_loss: 1.3839 - val_acc: 0.5102\n",
      "Epoch 395/500\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.2597 - acc: 0.5661 - val_loss: 1.3812 - val_acc: 0.5116\n",
      "Epoch 396/500\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 1.2585 - acc: 0.5655 - val_loss: 1.3809 - val_acc: 0.5086\n",
      "Epoch 397/500\n",
      "50000/50000 [==============================] - 6s 117us/step - loss: 1.2576 - acc: 0.5670 - val_loss: 1.3788 - val_acc: 0.5101\n",
      "Epoch 398/500\n",
      "50000/50000 [==============================] - 8s 155us/step - loss: 1.2568 - acc: 0.5670 - val_loss: 1.3780 - val_acc: 0.5119\n",
      "Epoch 399/500\n",
      "50000/50000 [==============================] - 6s 128us/step - loss: 1.2563 - acc: 0.5676 - val_loss: 1.3827 - val_acc: 0.5082\n",
      "Epoch 400/500\n",
      "50000/50000 [==============================] - 7s 133us/step - loss: 1.2548 - acc: 0.5671 - val_loss: 1.3790 - val_acc: 0.5081\n",
      "Epoch 401/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.2543 - acc: 0.5675 - val_loss: 1.3788 - val_acc: 0.5107\n",
      "Epoch 402/500\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.2535 - acc: 0.5678 - val_loss: 1.3803 - val_acc: 0.5131\n",
      "Epoch 403/500\n",
      "50000/50000 [==============================] - 7s 140us/step - loss: 1.2527 - acc: 0.5679 - val_loss: 1.3744 - val_acc: 0.5143\n",
      "Epoch 404/500\n",
      "50000/50000 [==============================] - 6s 127us/step - loss: 1.2520 - acc: 0.5680 - val_loss: 1.3757 - val_acc: 0.5126\n",
      "Epoch 405/500\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.2512 - acc: 0.5689 - val_loss: 1.3799 - val_acc: 0.5100\n",
      "Epoch 406/500\n",
      "50000/50000 [==============================] - 6s 121us/step - loss: 1.2506 - acc: 0.5692 - val_loss: 1.3744 - val_acc: 0.5136\n",
      "Epoch 407/500\n",
      "50000/50000 [==============================] - 6s 120us/step - loss: 1.2498 - acc: 0.5688 - val_loss: 1.3797 - val_acc: 0.5091\n",
      "Epoch 408/500\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1.2491 - acc: 0.5707 - val_loss: 1.3754 - val_acc: 0.5120\n",
      "Epoch 409/500\n",
      "50000/50000 [==============================] - 7s 135us/step - loss: 1.2481 - acc: 0.5704 - val_loss: 1.3744 - val_acc: 0.5125\n",
      "Epoch 410/500\n",
      "50000/50000 [==============================] - 7s 136us/step - loss: 1.2473 - acc: 0.5690 - val_loss: 1.3742 - val_acc: 0.5142\n",
      "Epoch 411/500\n",
      "50000/50000 [==============================] - 6s 118us/step - loss: 1.2465 - acc: 0.5713 - val_loss: 1.3769 - val_acc: 0.5097\n",
      "Epoch 412/500\n",
      "50000/50000 [==============================] - 6s 129us/step - loss: 1.2460 - acc: 0.5710 - val_loss: 1.3741 - val_acc: 0.5155\n",
      "Epoch 413/500\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.2451 - acc: 0.5716 - val_loss: 1.3743 - val_acc: 0.5120\n",
      "Epoch 414/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.2448 - acc: 0.5712 - val_loss: 1.3745 - val_acc: 0.5132\n",
      "Epoch 415/500\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.2435 - acc: 0.5724 - val_loss: 1.3758 - val_acc: 0.5134\n",
      "Epoch 416/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.2428 - acc: 0.5715 - val_loss: 1.3756 - val_acc: 0.5103\n",
      "Epoch 417/500\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 1.2420 - acc: 0.5729 - val_loss: 1.3759 - val_acc: 0.5149\n",
      "Epoch 418/500\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.2417 - acc: 0.5719 - val_loss: 1.3810 - val_acc: 0.5125\n",
      "Epoch 419/500\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.2408 - acc: 0.5727 - val_loss: 1.3719 - val_acc: 0.5121\n",
      "Epoch 420/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.2399 - acc: 0.5747 - val_loss: 1.3712 - val_acc: 0.5138\n",
      "Epoch 421/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.2390 - acc: 0.5728 - val_loss: 1.3703 - val_acc: 0.5135\n",
      "Epoch 422/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.2385 - acc: 0.5726 - val_loss: 1.3688 - val_acc: 0.5151\n",
      "Epoch 423/500\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 1.2372 - acc: 0.5746 - val_loss: 1.3700 - val_acc: 0.5134\n",
      "Epoch 424/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.2368 - acc: 0.5740 - val_loss: 1.3840 - val_acc: 0.5074\n",
      "Epoch 425/500\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.2358 - acc: 0.5742 - val_loss: 1.3693 - val_acc: 0.5160\n",
      "Epoch 426/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.2354 - acc: 0.5752 - val_loss: 1.3712 - val_acc: 0.5116\n",
      "Epoch 427/500\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 1.2346 - acc: 0.5754 - val_loss: 1.3742 - val_acc: 0.5107\n",
      "Epoch 428/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.2337 - acc: 0.5749 - val_loss: 1.3712 - val_acc: 0.5135\n",
      "Epoch 429/500\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 1.2327 - acc: 0.5760 - val_loss: 1.3697 - val_acc: 0.5169\n",
      "Epoch 430/500\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.2320 - acc: 0.5760 - val_loss: 1.3687 - val_acc: 0.5133\n",
      "Epoch 431/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.2312 - acc: 0.5770 - val_loss: 1.3683 - val_acc: 0.5179\n",
      "Epoch 432/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.2310 - acc: 0.5754 - val_loss: 1.3695 - val_acc: 0.5105\n",
      "Epoch 433/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.2302 - acc: 0.5760 - val_loss: 1.3666 - val_acc: 0.5139\n",
      "Epoch 434/500\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.2296 - acc: 0.5768 - val_loss: 1.3645 - val_acc: 0.5144\n",
      "Epoch 435/500\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.2285 - acc: 0.5773 - val_loss: 1.3667 - val_acc: 0.5145\n",
      "Epoch 436/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.2276 - acc: 0.5779 - val_loss: 1.3691 - val_acc: 0.5139\n",
      "Epoch 437/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.2267 - acc: 0.5781 - val_loss: 1.3651 - val_acc: 0.5144\n",
      "Epoch 438/500\n",
      "50000/50000 [==============================] - 6s 119us/step - loss: 1.2261 - acc: 0.5787 - val_loss: 1.3658 - val_acc: 0.5153\n",
      "Epoch 439/500\n",
      "50000/50000 [==============================] - 7s 131us/step - loss: 1.2256 - acc: 0.5791 - val_loss: 1.3664 - val_acc: 0.5144\n",
      "Epoch 440/500\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.2251 - acc: 0.5792 - val_loss: 1.3639 - val_acc: 0.5127\n",
      "Epoch 441/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.2235 - acc: 0.5792 - val_loss: 1.3659 - val_acc: 0.5149\n",
      "Epoch 442/500\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 1.2229 - acc: 0.5793 - val_loss: 1.3626 - val_acc: 0.5151\n",
      "Epoch 443/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.2224 - acc: 0.5794 - val_loss: 1.3629 - val_acc: 0.5169\n",
      "Epoch 444/500\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.2217 - acc: 0.5791 - val_loss: 1.3663 - val_acc: 0.5130\n",
      "Epoch 445/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.2211 - acc: 0.5810 - val_loss: 1.3626 - val_acc: 0.5162\n",
      "Epoch 446/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.2200 - acc: 0.5792 - val_loss: 1.3681 - val_acc: 0.5140\n",
      "Epoch 447/500\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 1.2190 - acc: 0.5819 - val_loss: 1.3678 - val_acc: 0.5141\n",
      "Epoch 448/500\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.2186 - acc: 0.5804 - val_loss: 1.3625 - val_acc: 0.5146\n",
      "Epoch 449/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.2182 - acc: 0.5807 - val_loss: 1.3662 - val_acc: 0.5156\n",
      "Epoch 450/500\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.2170 - acc: 0.5823 - val_loss: 1.3645 - val_acc: 0.5147\n",
      "Epoch 451/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.2163 - acc: 0.5825 - val_loss: 1.3654 - val_acc: 0.5143\n",
      "Epoch 452/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.2163 - acc: 0.5807 - val_loss: 1.3622 - val_acc: 0.5145\n",
      "Epoch 453/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.2151 - acc: 0.5824 - val_loss: 1.3741 - val_acc: 0.5134\n",
      "Epoch 454/500\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.2142 - acc: 0.5824 - val_loss: 1.3626 - val_acc: 0.5147\n",
      "Epoch 455/500\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.2133 - acc: 0.5833 - val_loss: 1.3615 - val_acc: 0.5142\n",
      "Epoch 456/500\n",
      "50000/50000 [==============================] - 6s 112us/step - loss: 1.2130 - acc: 0.5827 - val_loss: 1.3631 - val_acc: 0.5145\n",
      "Epoch 457/500\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 1.2118 - acc: 0.5836 - val_loss: 1.3625 - val_acc: 0.5156\n",
      "Epoch 458/500\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.2114 - acc: 0.5831 - val_loss: 1.3583 - val_acc: 0.5141\n",
      "Epoch 459/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.2106 - acc: 0.5847 - val_loss: 1.3581 - val_acc: 0.5165\n",
      "Epoch 460/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.2102 - acc: 0.5848 - val_loss: 1.3577 - val_acc: 0.5177\n",
      "Epoch 461/500\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.2096 - acc: 0.5847 - val_loss: 1.3558 - val_acc: 0.5171\n",
      "Epoch 462/500\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.2081 - acc: 0.5848 - val_loss: 1.3655 - val_acc: 0.5159\n",
      "Epoch 463/500\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.2081 - acc: 0.5847 - val_loss: 1.3558 - val_acc: 0.5174\n",
      "Epoch 464/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.2068 - acc: 0.5862 - val_loss: 1.3571 - val_acc: 0.5181\n",
      "Epoch 465/500\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.2062 - acc: 0.5864 - val_loss: 1.3563 - val_acc: 0.5176\n",
      "Epoch 466/500\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 1.2054 - acc: 0.5853 - val_loss: 1.3608 - val_acc: 0.5156\n",
      "Epoch 467/500\n",
      "50000/50000 [==============================] - 6s 115us/step - loss: 1.2052 - acc: 0.5866 - val_loss: 1.3587 - val_acc: 0.5166\n",
      "Epoch 468/500\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 1.2036 - acc: 0.5867 - val_loss: 1.3661 - val_acc: 0.5173\n",
      "Epoch 469/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.2034 - acc: 0.5867 - val_loss: 1.3563 - val_acc: 0.5191\n",
      "Epoch 470/500\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 1.2028 - acc: 0.5878 - val_loss: 1.3644 - val_acc: 0.5132\n",
      "Epoch 471/500\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.2016 - acc: 0.5879 - val_loss: 1.3575 - val_acc: 0.5159\n",
      "Epoch 472/500\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.2010 - acc: 0.5876 - val_loss: 1.3575 - val_acc: 0.5182\n",
      "Epoch 473/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.2000 - acc: 0.5877 - val_loss: 1.3546 - val_acc: 0.5206\n",
      "Epoch 474/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.1997 - acc: 0.5884 - val_loss: 1.3554 - val_acc: 0.5202\n",
      "Epoch 475/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.1986 - acc: 0.5894 - val_loss: 1.3584 - val_acc: 0.5147\n",
      "Epoch 476/500\n",
      "50000/50000 [==============================] - 6s 110us/step - loss: 1.1983 - acc: 0.5889 - val_loss: 1.3568 - val_acc: 0.5168\n",
      "Epoch 477/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.1973 - acc: 0.5895 - val_loss: 1.3530 - val_acc: 0.5173\n",
      "Epoch 478/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.1966 - acc: 0.5895 - val_loss: 1.3561 - val_acc: 0.5185\n",
      "Epoch 479/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.1960 - acc: 0.5900 - val_loss: 1.3644 - val_acc: 0.5160\n",
      "Epoch 480/500\n",
      "50000/50000 [==============================] - 6s 113us/step - loss: 1.1953 - acc: 0.5902 - val_loss: 1.3520 - val_acc: 0.5182\n",
      "Epoch 481/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.1942 - acc: 0.5897 - val_loss: 1.3511 - val_acc: 0.5188\n",
      "Epoch 482/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.1935 - acc: 0.5911 - val_loss: 1.3559 - val_acc: 0.5222\n",
      "Epoch 483/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.1931 - acc: 0.5908 - val_loss: 1.3611 - val_acc: 0.5168\n",
      "Epoch 484/500\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.1925 - acc: 0.5903 - val_loss: 1.3541 - val_acc: 0.5185\n",
      "Epoch 485/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.1920 - acc: 0.5916 - val_loss: 1.3484 - val_acc: 0.5215\n",
      "Epoch 486/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.1904 - acc: 0.5920 - val_loss: 1.3628 - val_acc: 0.5137\n",
      "Epoch 487/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.1906 - acc: 0.5916 - val_loss: 1.3600 - val_acc: 0.5210\n",
      "Epoch 488/500\n",
      "50000/50000 [==============================] - 6s 114us/step - loss: 1.1900 - acc: 0.5918 - val_loss: 1.3506 - val_acc: 0.5179\n",
      "Epoch 489/500\n",
      "50000/50000 [==============================] - 6s 111us/step - loss: 1.1889 - acc: 0.5922 - val_loss: 1.3558 - val_acc: 0.5164\n",
      "Epoch 490/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.1884 - acc: 0.5931 - val_loss: 1.3512 - val_acc: 0.5208\n",
      "Epoch 491/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.1876 - acc: 0.5927 - val_loss: 1.3495 - val_acc: 0.5196\n",
      "Epoch 492/500\n",
      "50000/50000 [==============================] - 5s 107us/step - loss: 1.1862 - acc: 0.5933 - val_loss: 1.3483 - val_acc: 0.5208\n",
      "Epoch 493/500\n",
      "50000/50000 [==============================] - 5s 110us/step - loss: 1.1860 - acc: 0.5939 - val_loss: 1.3497 - val_acc: 0.5213\n",
      "Epoch 494/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.1851 - acc: 0.5939 - val_loss: 1.3515 - val_acc: 0.5184\n",
      "Epoch 495/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.1844 - acc: 0.5939 - val_loss: 1.3545 - val_acc: 0.5176\n",
      "Epoch 496/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.1837 - acc: 0.5935 - val_loss: 1.3501 - val_acc: 0.5194\n",
      "Epoch 497/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.1827 - acc: 0.5946 - val_loss: 1.3499 - val_acc: 0.5202\n",
      "Epoch 498/500\n",
      "50000/50000 [==============================] - 5s 108us/step - loss: 1.1825 - acc: 0.5938 - val_loss: 1.3492 - val_acc: 0.5204\n",
      "Epoch 499/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.1819 - acc: 0.5947 - val_loss: 1.3503 - val_acc: 0.5202\n",
      "Epoch 500/500\n",
      "50000/50000 [==============================] - 5s 109us/step - loss: 1.1807 - acc: 0.5945 - val_loss: 1.3475 - val_acc: 0.5236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e9ac18d9c8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "設定要訓練的 Epoch 數\n",
    "\"\"\"\n",
    "model.fit(x_train, y_train, \n",
    "          epochs=500, \n",
    "          batch_size=256, \n",
    "          validation_data=(x_test, y_test), \n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 以視覺畫方式檢視訓練過程\n",
    "\n",
    "train_loss = model.history.history[\"loss\"]\n",
    "valid_loss = model.history.history[\"val_loss\"]\n",
    "\n",
    "train_acc = model.history.history[\"acc\"]\n",
    "valid_acc = model.history.history[\"val_acc\"]\n",
    "\n",
    "plt.plot(range(len(train_loss)), train_loss, label=\"train loss\")\n",
    "plt.plot(range(len(valid_loss)), valid_loss, label=\"valid loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(train_acc)), train_acc, label=\"train accuracy\")\n",
    "plt.plot(range(len(valid_acc)), valid_acc, label=\"valid accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
